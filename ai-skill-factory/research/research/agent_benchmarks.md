# Agentic Coding Benchmarks

## Purpose
Benchmarks evaluate how agents perform on:
- Multi-file edits
- Long-horizon tasks
- Tool usage

## Findings Across Studies
- Agents benefit from explicit procedural guidance
- Reusable skills improve consistency
- Tool boundaries reduce hallucinations

## Implication for Skills
Skills should:
- Break tasks into atomic steps
- Provide verification checks
- Encourage incremental commits

## Relevance
Supports design of production-grade agent skills for enterprise workflows.
